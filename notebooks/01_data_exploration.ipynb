{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RaceIQ Pro - Data Exploration\n",
    "\n",
    "This notebook demonstrates how to load and explore the race data using RaceIQ Pro's data pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path.cwd().parent / \"src\"))\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pipeline.data_loader import DataLoader, load_data_for_track\n",
    "from pipeline.validator import DataValidator\n",
    "from pipeline.feature_engineer import FeatureEngineer\n",
    "from utils.metrics import *\n",
    "from utils.visualization import *\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "loader = DataLoader()\n",
    "\n",
    "# Load all sample data\n",
    "data = loader.load_all_sample_data()\n",
    "\n",
    "print(\"Loaded datasets:\")\n",
    "for key, df in data.items():\n",
    "    print(f\"  {key}: {len(df)} records, {len(df.columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Validate Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize validator\n",
    "validator = DataValidator()\n",
    "\n",
    "# Validate all datasets\n",
    "validation_results = validator.validate_all(data)\n",
    "\n",
    "# Print summary\n",
    "print(validator.get_summary_report())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explore Lap Time Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine lap time data\n",
    "if 'lap_time' in data:\n",
    "    lap_df = data['lap_time']\n",
    "    print(\"Lap Time Data:\")\n",
    "    print(lap_df.head())\n",
    "    print(\"\\nData types:\")\n",
    "    print(lap_df.dtypes)\n",
    "    print(\"\\nBasic statistics:\")\n",
    "    print(lap_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explore Section Analysis Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine section analysis data\n",
    "if 'section_analysis' in data:\n",
    "    section_df = data['section_analysis']\n",
    "    print(\"Section Analysis Data:\")\n",
    "    print(section_df.head())\n",
    "    print(\"\\nDrivers in dataset:\")\n",
    "    print(section_df['DRIVER_NUMBER'].unique())\n",
    "    print(\"\\nLap time statistics:\")\n",
    "    print(section_df['LAP_TIME_SECONDS'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature engineer\n",
    "engineer = FeatureEngineer()\n",
    "\n",
    "# Engineer features for all datasets\n",
    "engineered_data = engineer.engineer_all_features(data)\n",
    "\n",
    "print(\"Feature engineering complete!\")\n",
    "if 'section_analysis' in engineered_data:\n",
    "    print(\"\\nNew columns in section analysis:\")\n",
    "    original_cols = set(data['section_analysis'].columns)\n",
    "    new_cols = set(engineered_data['section_analysis'].columns) - original_cols\n",
    "    for col in sorted(new_cols):\n",
    "        print(f\"  - {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot lap times if data is available\n",
    "if 'section_analysis' in engineered_data:\n",
    "    section_df = engineered_data['section_analysis']\n",
    "    \n",
    "    # Select a few drivers for visualization\n",
    "    drivers = section_df['DRIVER_NUMBER'].unique()[:5]\n",
    "    \n",
    "    # Plot lap times\n",
    "    fig = plot_lap_times(\n",
    "        section_df,\n",
    "        driver_col='DRIVER_NUMBER',\n",
    "        lap_col='LAP_NUMBER',\n",
    "        time_col='LAP_TIME_SECONDS',\n",
    "        drivers=drivers,\n",
    "        title=\"Lap Times - Barber Motorsports Park Race 1\"\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sector comparison\n",
    "if 'section_analysis' in engineered_data:\n",
    "    fig = plot_sector_comparison(\n",
    "        section_df,\n",
    "        driver_col='DRIVER_NUMBER',\n",
    "        drivers=drivers\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate theoretical best laps\n",
    "if 'section_analysis' in engineered_data:\n",
    "    theoretical_best = calculate_theoretical_best_lap(\n",
    "        section_df,\n",
    "        driver_col='DRIVER_NUMBER'\n",
    "    )\n",
    "    print(\"Theoretical Best Lap Times:\")\n",
    "    print(theoretical_best.sort_values('theoretical_best_lap').head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate driver consistency\n",
    "if 'section_analysis' in engineered_data:\n",
    "    consistency = calculate_driver_consistency(section_df)\n",
    "    print(\"Driver Consistency Scores:\")\n",
    "    print(consistency[['DRIVER_NUMBER', 'consistency_score', 'lap_time_cv']].sort_values('consistency_score', ascending=False).head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
